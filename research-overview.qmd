---
  title: "My research"
---


My current research develops general principled frameworks for **robust statistical inference** and **exploratory data analysis** that have applications in a variety of fields like **genomics, neuroscience, and social science**. I am developing theoretically motivated Bayesian and frequentist frameworks to **robustly fit likelihood-based models** that may be misspecified. This methodology is relevant in the current age where we tend to have **big data** that is potentially biased or corrupted (e.g. arising in surveys, health records, etc.). I have also developed new exploratory data analysis methods, e.g. those based on novel **Bayesian density-based clustering** and **iterative-testing** to find combinatorial structures (e.g. networks) for integration of multi-view data. Given my strong background in **stochastic processes** and **large deviation theory**, in the future I aim to develop methods for analysis of time series data and for data assimilation problems that arise in climate modeling.


<!--
I have training in probability theory, statistical inference, and computer science. I am excited to apply these tools to address important practical problems. My long-term research goal is to improve our understanding of stochastic models for complex systems like climate, markets, etc. that are determined by a large number of factors. I want to pursue both the theoretical study of such models and their sound statistical inference based on observational data.

Mathematical models for complex systems are generally intractable, being governed by a large number of interactions or agents. However, one can often describe the limiting behavior of such systems when the number of interactions is large. This is similar to the idea from statistical mechanics that we can describe macroscopic behavior well (e.g. via Ideal gas laws) even if the microscopic behavior cannot be predicted. You can find examples of this in my work on [controlling a population](https://lmcs.episciences.org/5647) of identical agents and [large-scale load balancing using random routing with choice](https://projecteuclid.org/journals/annals-of-applied-probability/volume-32/issue-3/Near-equilibrium-fluctuations-for-supermarket-models-with-growing-choices/10.1214/21-AAP1729.short). Note that both these analyses use very different mathematical techniques: while the former analysis is combinatorial and algorithmic, the latter uses probabilistic tools like stochastic calculus and martingale central limit theorem.

Naturally, any mathematical model will only be a rough approximation to reality. This is particularly going to be true of simple models that are meant to capture core ideas or any model that uses idealistic assumptions like Gaussianity.

Here in an overview of some of my research directions.

### Power of Choice and other rules for bounded rationality

In the age of massive computational power and data availablity, finding increasingly **optimal solutions** to problems has become possible. However, many resource limited systems (including human beings) can only spend a limited amount on being rational. How then can we make good decisions with limited processing power? One such rule is the power of choice, which roughly says that over the long term, having some choice in the rewards you obtain provides vastly improves your aggregate performance than having no choice. Another, such rule could be called patience, i.e. to avoid action until a favorable circumstance arises. Another such rule, can be having a trade-off between exploration (training) and exploitation (utilization) â€” spend some time on doing something that is pointless.

In my work, I study simple mathematical models where these rules show benefit. Power choice has been useful for load balancing. I am currently studying its effects on reducing economic inequality. The rule of patience can be seen in a Metropolis Hasting's sampler that can sample from a desired posterior distribution with a simple rule of accepting or rejecting a proposal with a simple probability. The exploration and exploitation trade-off has been seen in the popular multi-armed bandit problem.

In fact, may rules for bounded rationality are common sense sayings that already passed down generations to us like tit for tat (in discussing how to interact with people), try and try till you succeed (on the importance of allowing for failure), measure twice cut once, a stitch in time saves nine, don't be a jack of all and master of none etc. I would like to find mathematical models to quantify the effects of these rules. Thus I want to rigorously study the mathematical properties and perform statistical inference based on the field of [bounded rationality](https://en.wikipedia.org/wiki/Bounded_rationality).

### Robust Model Fitting

### Bayesian Clustering

### Iterative testing

### Computer Science
-->