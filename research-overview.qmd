---
  title: "My research"
---

My long term research goal is to improve stochastic models for complex systems like weather, markets, human brain, etc. that are determined by a large number of factors. I wants to design interpretable mathematical models and sound statistical inference techniques to improve our scientific understanding of these systems.

Mathematical models for complex systems are intractable, being typically governed by a large number of factors. However, one can often describe the limiting behavior of such systems when the number of factors is large. This is similar to the idea from statistical mechanics that we can describe macroscopic behavior well (e.g. ideal gas laws) even if the microscopic behavior is harder to study. You can find examples of this in my work on [controlling a  population of identical agents](https://lmcs.episciences.org/5647) and [load balancing using randomized routing](https://projecteuclid.org/journals/annals-of-applied-probability/volume-32/issue-3/Near-equilibrium-fluctuations-for-supermarket-models-with-growing-choices/10.1214/21-AAP1729.short). In this direction, motivated by the search for a more realistic model for the design of data centers, I am  currently studying a model for load balancing on networks.

Naturally, even our best mathematical models can only approximate real systems. This is particularly true of models that manage to capture core mechanisms by making reasonable assumptions for mathematical tractability like Gaussianity, independence, exponentially distributed event times, etc. However it is not clear how to do statistical inference for  these models after acknowledging that our model may indeed only be an approximation. Motivated by the coarsened inference framework of [Miller and Dunson](https://www.tandfonline.com/doi/abs/10.1080/01621459.2018.1469995), I  proposed the [principle of optimism in data analysis](https://arxiv.org/abs/2303.10525), which states that one should allow some degree of data re-interpretation to improve inference of approximate models. Along with the theory behind this principle, he is developing practical methods for statistical inference of approximate models and applying it to problems in economics and neuroscience. Apart from this, I am  also developing principled statistical frameworks for novel exploratory data analysis tasks like [clustering with uncertainty](https://arxiv.org/abs/2403.04912v1) and [extracting statistically informative networks from noisy data](https://www.jmlr.org/papers/volume24/22-0581/22-0581.pdf).

<!--
Here in an overview of some of my research directions.

### Power of Choice and rules for bounded rationality
In the age of massive computational power and data availablity, finding increasingly **optimal solutions** to problems has become possible. However, many resource limited systems (including human beings) can only spend a limited amount on being rational. How then can we make good decisions with limited processing power? One such rule is the power of choice, which roughly says that over the long term, having some choice in the rewards you obtain provides vastly improves your aggregate performance than having no choice. Another, such rule could be called patience, i.e. to avoid action until a favorable circumstance arises. Another such rule, can be having a trade-off between exploration (training) and exploitation (utilization) â€” spend some time on doing something that is pointless.

In my work, I study simple mathematical models where these rules show benefit. Power choice has been useful for load balancing. I am currently studying its effects on reducing economic inequality. The rule of patience can be seen in a Metropolis Hasting's sampler that can sample from a desired posterior distribution with a simple rule of accepting or rejecting a proposal with a simple probability. The exploration and exploitation trade-off has been seen in the popular multi-armed bandit problem.

In fact, may rules for [bounded rationality](https://plato.stanford.edu/entries/bounded-rationality/) are common sense sayings that already passed down generations to us like tit for tat (in discussing how to interact with people), try and try till you succeed (on the importance of allowing for failure), measure twice cut once, a stitch in time saves nine, don't be a jack of all and master of none etc. I would like to find mathematical models to quantify the effects of these rules. Thus I want to rigorously study the mathematical properties and perform statistical inference based on the field of [bounded rationality](https://en.wikipedia.org/wiki/Bounded_rationality).
-->